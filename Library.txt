Libraries :

# Document loading, retrieval methods and text splitting
pip install -qU langchain langchain_community

# Local vector store via Chroma
pip install -qU langchain_chroma

# Local inference and embeddings via Ollama
pip install -qU langchain_ollama



from langchain_community.document_loaders import PyMuPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma
from langchain_ollama import OllamaEmbeddings
from langchain_ollama import ChatOllama


For running ollama in your pc :

1)ollama 
2)ollama list 
3)ollama run deepseek-r1:1.5b
4)ollama pull nomic-embed-text
5)ollama serve [to run the llm model and embed model]